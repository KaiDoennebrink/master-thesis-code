{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using pretext tasks for active learning\n",
    "\n",
    "In this notebook I want to use a simple pretext task to train an Inception network.\n",
    "This pre-trained Inception network can later be used as a starting point with a different classification head for training an ECG classifier.\n",
    "Furthermore, the losses of the model can be used as selection criteria at the beginning of a new active learning cycle.\n",
    "\n",
    "## Setup\n",
    "Utilize more of the GPU memory so that I can use bigger batches."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4d750d15adf226c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepal_for_ecg.util import improve_gpu_capacity\n",
    "\n",
    "improve_gpu_capacity()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "688632de72bedd18",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pretext task\n",
    "To train the network in a self-supervised fashion the labels have to come from the data itself.\n",
    "A pretext task for learning ECG representations suggested by Sarkar and Etemad (2022) is transformation recognition of six different signal transformations applied to the ECG signal.\n",
    "The six signal transformations are noise addition, scaling, negation, temporal inversion, permutation, and time-warping.\n",
    "\n",
    "## Data\n",
    "\n",
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d6aeb109f5f59df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from deepal_for_ecg.data.load import PTBXLDataLoader\n",
    "\n",
    "loader = PTBXLDataLoader(saved_data_base_dir=\"../data/saved/\", load_saved_data=True)\n",
    "loader.load_data()\n",
    "\n",
    "signal_data = loader.X_train.astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a641dc91c0f8dfd0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# since we do not need the other data we reduce the memory footprint by deleting the loader\n",
    "del loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2df7cf3e6b75eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate the transformed data\n",
    "\n",
    "Use the TransformationRecognitionDataModule to generate the transformed data and split it into training, test and validation datasets.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18e8b0103ecd75f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepal_for_ecg.data.tranformation_recognition import TransformationRecognitionDataModule\n",
    "\n",
    "data_module = TransformationRecognitionDataModule()\n",
    "# uncomment the following lines to initially generate the data\n",
    "# data_module.generate_and_split_data(signal_data)\n",
    "# data_module.prepare_datasets()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86b798b806541540",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect the data transformation\n",
    "\n",
    "To have a better understanding of the data transform a random signal and visualize it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9181c99390703826"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from deepal_for_ecg.data.augmentation import noise_addition, scaling, negation, temporal_inversion, permutation, time_warping\n",
    "\n",
    "sample_idx = np.random.randint(signal_data.shape[0])\n",
    "channel_idx = np.random.randint(signal_data.shape[-1])\n",
    "\n",
    "selected_signal = np.expand_dims(signal_data[sample_idx], axis=0)\n",
    "\n",
    "noisy_data = noise_addition(selected_signal)\n",
    "scaled_data = scaling(selected_signal)\n",
    "negation_data = negation(selected_signal)\n",
    "temporal_inversed_data = temporal_inversion(selected_signal)\n",
    "permuted_data = permutation(selected_signal)\n",
    "time_warped_data = time_warping(selected_signal)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9987da7dd8b55445",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visual inspection\n",
    "\n",
    "Visualize the transformations of a random channel of a random signal."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5e74c98965b320"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "fig.suptitle(f\"Original Signal and Transformed Signals (signal {sample_idx}, channel {channel_idx})\")\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "\n",
    "signals = [\n",
    "    noisy_data[0, :, channel_idx], \n",
    "    scaled_data[0, :, channel_idx], \n",
    "    negation_data[0, :, channel_idx], \n",
    "    temporal_inversed_data[0, :, channel_idx], \n",
    "    permuted_data[0, :, channel_idx], \n",
    "    time_warped_data[0, :, channel_idx]\n",
    "]\n",
    "transformation_labels = [\"noisy\", \"scaled\", \"negated\", \"temporal_inversed\", \"permuted\", \"time_warped\"]\n",
    "\n",
    "for i, (signal, label) in enumerate(zip(signals, transformation_labels)):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.plot(signal_data[sample_idx, :, channel_idx], label='original', color='blue')\n",
    "    plt.plot(signal, label=label, color='orange', alpha=0.5)\n",
    "    # plt.title(f'Transformed Signal {i+1}')\n",
    "    if i % 2 == 0:\n",
    "        plt.ylabel('Amplitude')\n",
    "    if i >= 4:\n",
    "        plt.xlabel('Time Steps')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5be183a2edead55",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "\n",
    "Load the Inception network model with the multi-task classification head."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71660e6e4bf82734"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepal_for_ecg.models.classification_heads import simple_classification_head\n",
    "from deepal_for_ecg.models.inception_network import InceptionNetworkBuilder, InceptionNetworkConfig\n",
    "\n",
    "config = InceptionNetworkConfig(create_classification_head=simple_classification_head, num_classes=7)\n",
    "builder = InceptionNetworkBuilder()\n",
    "model = builder.build_model(config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99dd68df162f3ee5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "Now I train the Inception network with the pretext task to create a good representation model.\n",
    "\n",
    "### Improve GPU capacity\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "140070144a55e76e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e3428b082c7972a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop\n",
    "\n",
    "inclusive saving the best model according to validation set\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df80661b1d9032db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adam optimizer with 0.0001 learning rate\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c420eb7a568d6529",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepal_for_ecg.data.augmentation import random_crop as rc\n",
    "\n",
    "model.fit(data_module.train_dataset.map(lambda x, y:(rc(x), y)).batch(128), epochs=epochs, batch_size=128, validation_data=data_module.validation_dataset.map(lambda x, y:(rc(x), y)).batch(128))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ddf6f17cf94bd35",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb168349ce9f5aed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batched_dataset = data_module.train_dataset.map(lambda x, y:(rc(x), y)).batch(128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1b42cefb5aaee71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for s, l in batched_dataset.take(1):\n",
    "    print(s.shape)\n",
    "    print(l.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d4f58fd9bfadb9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pretext task loss selection vs. random selection\n",
    "In this section I want to validate that the first selection of samples can be improved by using the pretext task loss.\n",
    "\n",
    "### Loading the best pretext task model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72dbce5289af8e98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "df22e0a865bbbc62"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate final losses\n",
    "\n",
    "Calculate the average losses of all transformations of the best pretext task model.\n",
    "TODO: Check if really the average was used"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7000b160ee88a9be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11b6d6d9ebc636e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split unlabeled pools\n",
    "Similar to Yi et al. (2022) split the unlabeled pool in multiple unlabeled pools to select the data from in each iteration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea6298e99918cdf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3115337fcf7b5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select initial samples\n",
    "Select the initial samples from the first unlabeled pool at uniform."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb8cf6fc02a0c5a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9aea09a039bae1ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the ECG classification network from scratch with these samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c653b9eb27e7c3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d69e72eb1a5e474"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tune the ECG classificator from the pre-trained model with these samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3faa1e34c26e9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "155a4596a087c7b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the ECG classificator from scratch with randomly chosen samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c2ac5177555eb4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "81a90a1ca9c751a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tune the ECG classificator from the pre-trained model with randomly chosen samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb0f3e90bc71bb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8a1a7f2cafdc9e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae48633abd875a4f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e43f76f95c988383"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
